{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35674a7a",
   "metadata": {},
   "source": [
    "##Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3ff107",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31559760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function dotenv.main.load_dotenv(dotenv_path: Union[str, ForwardRef('os.PathLike[str]'), NoneType] = None, stream: Optional[IO[str]] = None, verbose: bool = False, override: bool = False, interpolate: bool = True, encoding: Optional[str] = 'utf-8') -> bool>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4f2fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "print(os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8faed55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\GenAI-LangChain\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "openai_embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f5d1550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n",
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No languages specified, defaulting to English.\n",
      "Total Chunks: 7\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = DirectoryLoader(\"data/\", glob=\"**/*\")\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "doc_chunks = splitter.split_documents(documents)\n",
    "\n",
    "print(\"Total Chunks:\", len(doc_chunks))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "524c4854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Vector Length: 1536\n",
      "Sample Values: [0.015104802325367928, -0.01100511010736227, -0.008538889698684216, 0.041406888514757156, 0.011498354375362396, -0.05785689875483513, -0.01393895223736763, 0.030568325892090797, -0.04304676502943039, -0.04045883193612099]\n"
     ]
    }
   ],
   "source": [
    "embedding = openai_embeddings.embed_query(doc_chunks[0].page_content)\n",
    "\n",
    "print(\"Embedding Vector Length:\", len(embedding))\n",
    "print(\"Sample Values:\", embedding[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b678f948",
   "metadata": {},
   "source": [
    "Task 2 ---— Hugging Face Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eeae3641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.2.3-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in .\\venv\\lib\\site-packages (from sentence-transformers) (5.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in .\\venv\\lib\\site-packages (from sentence-transformers) (1.4.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in .\\venv\\lib\\site-packages (from sentence-transformers) (2.10.0)\n",
      "Requirement already satisfied: numpy in .\\venv\\lib\\site-packages (from sentence-transformers) (2.2.6)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.7.2-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: scipy in .\\venv\\lib\\site-packages (from sentence-transformers) (1.15.3)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in .\\venv\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Requirement already satisfied: tqdm in .\\venv\\lib\\site-packages (from sentence-transformers) (4.67.3)\n",
      "Requirement already satisfied: packaging>=20.0 in .\\venv\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in .\\venv\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in .\\venv\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2026.2.19)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in .\\venv\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in .\\venv\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.24.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in .\\venv\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
      "Requirement already satisfied: filelock in .\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.24.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in .\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2026.2.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in .\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in .\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in .\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.5.4)\n",
      "Requirement already satisfied: anyio in .\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (4.12.1)\n",
      "Requirement already satisfied: certifi in .\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in .\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in .\\venv\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in .\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (0.16.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in .\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in .\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in .\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in .\\venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in .\\venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in .\\venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub>=0.20.0->sentence-transformers) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in .\\venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in .\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: typer>=0.24.0 in .\\venv\\lib\\site-packages (from typer-slim->transformers<6.0.0,>=4.41.0->sentence-transformers) (0.24.0)\n",
      "Requirement already satisfied: click>=8.2.1 in .\\venv\\lib\\site-packages (from typer>=0.24.0->typer-slim->transformers<6.0.0,>=4.41.0->sentence-transformers) (8.3.1)\n",
      "Requirement already satisfied: rich>=12.3.0 in .\\venv\\lib\\site-packages (from typer>=0.24.0->typer-slim->transformers<6.0.0,>=4.41.0->sentence-transformers) (14.3.3)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in .\\venv\\lib\\site-packages (from typer>=0.24.0->typer-slim->transformers<6.0.0,>=4.41.0->sentence-transformers) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in .\\venv\\lib\\site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers<6.0.0,>=4.41.0->sentence-transformers) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in .\\venv\\lib\\site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->transformers<6.0.0,>=4.41.0->sentence-transformers) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in .\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->transformers<6.0.0,>=4.41.0->sentence-transformers) (0.1.2)\n",
      "Downloading sentence_transformers-5.2.3-py3-none-any.whl (494 kB)\n",
      "Downloading scikit_learn-1.7.2-cp310-cp310-win_amd64.whl (8.9 MB)\n",
      "   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.0/8.9 MB 6.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.4/8.9 MB 6.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.7/8.9 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.0/8.9 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.3/8.9 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.6/8.9 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.7/8.9 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.9/8.9 MB 5.7 MB/s  0:00:01\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn, sentence-transformers\n",
      "\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   ------------- -------------------------- 1/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [sentence-transformers]\n",
      "   -------------------------- ------------- 2/3 [sentence-transformers]\n",
      "   -------------------------- ------------- 2/3 [sentence-transformers]\n",
      "   -------------------------- ------------- 2/3 [sentence-transformers]\n",
      "   -------------------------- ------------- 2/3 [sentence-transformers]\n",
      "   -------------------------- ------------- 2/3 [sentence-transformers]\n",
      "   -------------------------- ------------- 2/3 [sentence-transformers]\n",
      "   -------------------------- ------------- 2/3 [sentence-transformers]\n",
      "   ---------------------------------------- 3/3 [sentence-transformers]\n",
      "\n",
      "Successfully installed scikit-learn-1.7.2 sentence-transformers-5.2.3 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7586fdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\GenAI-LangChain\\venv\\lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\hp\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 103/103 [00:00<00:00, 240.39it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF Vector Length: 384\n",
      "Sample Values: [-0.009657028131186962, 0.008480062708258629, -0.002803912851959467, -0.01811068132519722, -0.01980390027165413, -0.00885832030326128, 0.056905534118413925, -0.0323285311460495, -0.08476506918668747, 0.02724147029221058]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "hf_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "hf_embedding = hf_embeddings.embed_query(doc_chunks[0].page_content)\n",
    "\n",
    "print(\"HF Vector Length:\", len(hf_embedding))\n",
    "print(\"Sample Values:\", hf_embedding[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fd7585",
   "metadata": {},
   "source": [
    "Task 3 — ---OpenAI vs Hugging Face "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da91fcd9",
   "metadata": {},
   "source": [
    "When to prefer OpenAI?\n",
    "\n",
    "High quality semantic understanding\n",
    "\n",
    "Production-grade search\n",
    "\n",
    "No infra maintenance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59a1a96",
   "metadata": {},
   "source": [
    "Offline/local usage\n",
    "\n",
    "Cost-sensitive projects\n",
    "\n",
    "Full control over deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769ba994",
   "metadata": {},
   "source": [
    "Cost vs Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2f7d7e",
   "metadata": {},
   "source": [
    "Factor\tOpenAI\t        Hugging Face\n",
    "Cost\tPaid API\t    Free (local compute)\n",
    "Setup\tEasy\t        Slightly more setup\n",
    "Quality\tVery strong\t    Good\n",
    "Speed\tAPI dependent\tLocal GPU dependent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e653d2",
   "metadata": {},
   "source": [
    "Similarity Search (OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e8884b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create embeddings for all chunks\n",
    "chunk_texts = [doc.page_content for doc in doc_chunks]\n",
    "chunk_embeddings = openai_embeddings.embed_documents(chunk_texts)\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def search(query, top_k=3):\n",
    "    query_embedding = openai_embeddings.embed_query(query)\n",
    "    \n",
    "    similarities = [\n",
    "        cosine_similarity(query_embedding, emb)\n",
    "        for emb in chunk_embeddings\n",
    "    ]\n",
    "    \n",
    "    top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "    \n",
    "    return [doc_chunks[i].page_content for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e67686c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The quick brown fox jumps over the lazy dog.\\n\\nThis is the second line of the file.\\n\\nLangChain's TextLoader is great for simple text files.\\n\\nIt handles various encodings like UTF-8.\", 'Name Age City Occupation Alice 30 New York Software Engineer Bob 25 Los Angeles Data Scientist Charlie 35 Chicago Product Manager David 28 Houston UX Designer', '8. Blog / Thought Leadership Highlights\\n\\nProfessional headshots for business success\\n\\n\\n\\nImportance of visual storytelling in corporate branding\\n\\nTips for leveraging corporate videos for engagement\\n\\n9. Contact Information\\n\\nWebsite: Neuron.in\\n\\nContact form (highlighted visually)\\n\\n\\n\\nLocation: Noida, India\\n\\n\\n\\nSocial links (if available)\\n\\n10. Closing Page\\n\\n\\n\\nStrong brand statement: “With Neuron, your brand speaks visually.”\\n\\nCTA: “Explore our portfolio and elevate your business image today.”']\n",
      "[\"The quick brown fox jumps over the lazy dog.\\n\\nThis is the second line of the file.\\n\\nLangChain's TextLoader is great for simple text files.\\n\\nIt handles various encodings like UTF-8.\", '8. Blog / Thought Leadership Highlights\\n\\nProfessional headshots for business success\\n\\n\\n\\nImportance of visual storytelling in corporate branding\\n\\nTips for leveraging corporate videos for engagement\\n\\n9. Contact Information\\n\\nWebsite: Neuron.in\\n\\nContact form (highlighted visually)\\n\\n\\n\\nLocation: Noida, India\\n\\n\\n\\nSocial links (if available)\\n\\n10. Closing Page\\n\\n\\n\\nStrong brand statement: “With Neuron, your brand speaks visually.”\\n\\nCTA: “Explore our portfolio and elevate your business image today.”', \"1. Cover Page\\n\\n\\n\\nLogo (from website)\\n\\nTitle: Neuron – Corporate Photography & Video Solutions\\n\\nTagline: Visual storytelling for modern brands\\n\\nHero image from homepage\\n\\n2. About Neuron\\n\\n\\n\\nIntroduction from homepage: “Elevate your brand's presence with our bespoke corporate video production and professional headshots in Pune. At Neuron, we help you unleash the power of visual storytelling to connect with your audience and showcase your corporate identity like never before.”\"]\n",
      "['Positioning: #1 rated professional photographer in Pune (Google Reviews)\\n\\nVision & brand ethos\\n\\n3. Services Overview\\n\\nComprehensive solutions tailored for business growth and digital presence:\\n\\nCorporate Headshot Photography\\n\\nCorporate Video Production\\n\\nAd Films\\n\\nVideo Editing Service\\n\\nCorporate Video Profile\\n\\nInclude relevant visuals from the website for each service.\\n\\n4. Corporate Photography Services\\n\\n\\n\\nIndividual & Team Headshots\\n\\nOn-site office shoots\\n\\nExecutive portraits', \"1. Cover Page\\n\\n\\n\\nLogo (from website)\\n\\nTitle: Neuron – Corporate Photography & Video Solutions\\n\\nTagline: Visual storytelling for modern brands\\n\\nHero image from homepage\\n\\n2. About Neuron\\n\\n\\n\\nIntroduction from homepage: “Elevate your brand's presence with our bespoke corporate video production and professional headshots in Pune. At Neuron, we help you unleash the power of visual storytelling to connect with your audience and showcase your corporate identity like never before.”\", '8. Blog / Thought Leadership Highlights\\n\\nProfessional headshots for business success\\n\\n\\n\\nImportance of visual storytelling in corporate branding\\n\\nTips for leveraging corporate videos for engagement\\n\\n9. Contact Information\\n\\nWebsite: Neuron.in\\n\\nContact form (highlighted visually)\\n\\n\\n\\nLocation: Noida, India\\n\\n\\n\\nSocial links (if available)\\n\\n10. Closing Page\\n\\n\\n\\nStrong brand statement: “With Neuron, your brand speaks visually.”\\n\\nCTA: “Explore our portfolio and elevate your business image today.”']\n"
     ]
    }
   ],
   "source": [
    "print(search(\"What is machine learning?\"))\n",
    "print(search(\"Explain embeddings\"))\n",
    "print(search(\"Information about company policy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ad88b1",
   "metadata": {},
   "source": [
    "LangChain Abstraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a30706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24a88da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown fox jumps over the lazy dog.\n",
      "\n",
      "This is the second line of the file.\n",
      "\n",
      "LangChain's TextLoader is great for simple text files.\n",
      "\n",
      "It handles various encodings like UTF-8.\n",
      "--------------------------------------------------\n",
      "1. Cover Page\n",
      "\n",
      "\n",
      "\n",
      "Logo (from website)\n",
      "\n",
      "Title: Neuron – Corporate Photography & Video Solutions\n",
      "\n",
      "Tagline: Visual storytelling for modern brands\n",
      "\n",
      "Hero image from homepage\n",
      "\n",
      "2. About Neuron\n",
      "\n",
      "\n",
      "\n",
      "Introduction from homepage: “Elevate your brand's presence with our bespoke corporate video production and professional headshots in Pune. At Neuron, we help you unleash the power of visual storytelling to connect with your audience and showcase your corporate identity like never before.”\n",
      "--------------------------------------------------\n",
      "o Mortal, Thug, Yatin Karyekar, Tisca Chopra, Sumedh Mudgalkar, Dynamo, Scout,\n",
      "\n",
      "Regaltos, etc.\n",
      "\n",
      "Corporate clients: Leading brands in tech and imaging\n",
      "\n",
      "\n",
      "\n",
      "Include images of client work and celebrity shoots\n",
      "\n",
      "7. Why Choose Neuron\n",
      "\n",
      "Custom packages for budget & objectives\n",
      "\n",
      "Transform corporate image & marketing efforts\n",
      "\n",
      "Exceptional value without compromising quality\n",
      "\n",
      "Proven results reflected in #1 Google ranking\n",
      "\n",
      "8. Blog / Thought Leadership Highlights\n",
      "\n",
      "Professional headshots for business success\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(doc_chunks, openai_embeddings)\n",
    "\n",
    "results = vectorstore.similarity_search(\"What is quick brown fox?\", k=3)\n",
    "\n",
    "for r in results:\n",
    "    print(r.page_content)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fddb8ab",
   "metadata": {},
   "source": [
    "Ollama Embeddings (Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffacb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd904e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_8644\\1934778286.py:3: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import OllamaEmbeddings``.\n",
      "  ollama_embeddings = OllamaEmbeddings(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama Vector Length: 768\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "ollama_embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\"\n",
    ")\n",
    "\n",
    "ollama_vector = ollama_embeddings.embed_query(\n",
    "    doc_chunks[0].page_content\n",
    ")\n",
    "\n",
    "print(\"Ollama Vector Length:\", len(ollama_vector))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f57d3e",
   "metadata": {},
   "source": [
    "Model\tInternet Required\tCost\tSpeed\n",
    "OpenAI\tYes\tPaid\tFast\n",
    "Ollama\tNo\tFree\tDepends on CPU/GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf656eb",
   "metadata": {},
   "source": [
    "Task 7 --- FAISS Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81bd5879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='6b5f965e-e157-4963-a5dd-edd1e064a128', metadata={'source': 'data\\\\sample.txt'}, page_content=\"The quick brown fox jumps over the lazy dog.\\n\\nThis is the second line of the file.\\n\\nLangChain's TextLoader is great for simple text files.\\n\\nIt handles various encodings like UTF-8.\"),\n",
       " Document(id='110700a8-22f9-4587-8598-eebfbc40d7a2', metadata={'source': 'data\\\\sample.pdf'}, page_content='8. Blog / Thought Leadership Highlights\\n\\nProfessional headshots for business success\\n\\n\\n\\nImportance of visual storytelling in corporate branding\\n\\nTips for leveraging corporate videos for engagement\\n\\n9. Contact Information\\n\\nWebsite: Neuron.in\\n\\nContact form (highlighted visually)\\n\\n\\n\\nLocation: Noida, India\\n\\n\\n\\nSocial links (if available)\\n\\n10. Closing Page\\n\\n\\n\\nStrong brand statement: “With Neuron, your brand speaks visually.”\\n\\nCTA: “Explore our portfolio and elevate your business image today.”'),\n",
       " Document(id='33ce6f45-740d-4af3-a776-4cb0caa0b0e3', metadata={'source': 'data\\\\sample.pdf'}, page_content=\"1. Cover Page\\n\\n\\n\\nLogo (from website)\\n\\nTitle: Neuron – Corporate Photography & Video Solutions\\n\\nTagline: Visual storytelling for modern brands\\n\\nHero image from homepage\\n\\n2. About Neuron\\n\\n\\n\\nIntroduction from homepage: “Elevate your brand's presence with our bespoke corporate video production and professional headshots in Pune. At Neuron, we help you unleash the power of visual storytelling to connect with your audience and showcase your corporate identity like never before.”\")]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "faiss_store = FAISS.from_documents(doc_chunks, openai_embeddings)\n",
    "\n",
    "# Similarity search\n",
    "results = faiss_store.similarity_search(\"Explain embeddings\", k=3)\n",
    "\n",
    "# Save locally\n",
    "faiss_store.save_local(\"faiss_index\")\n",
    "\n",
    "# Reload\n",
    "loaded_store = FAISS.load_local(\n",
    "    \"faiss_index\",\n",
    "    openai_embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "loaded_store.similarity_search(\"Explain embeddings\", k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921e79c7",
   "metadata": {},
   "source": [
    "Task 8 —--- ChromaDB Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6768fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f18054a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python-dotenv could not parse statement starting at line 2\n",
      "python-dotenv could not parse statement starting at line 2\n",
      "python-dotenv could not parse statement starting at line 2\n",
      "python-dotenv could not parse statement starting at line 2\n",
      "python-dotenv could not parse statement starting at line 2\n",
      "python-dotenv could not parse statement starting at line 2\n",
      "python-dotenv could not parse statement starting at line 2\n",
      "python-dotenv could not parse statement starting at line 2\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_8644\\1070730962.py:9: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  chroma_store.persist()\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_8644\\1070730962.py:12: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.\n",
      "  chroma_loaded = Chroma(\n",
      "python-dotenv could not parse statement starting at line 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\sample.txt'}, page_content=\"The quick brown fox jumps over the lazy dog.\\n\\nThis is the second line of the file.\\n\\nLangChain's TextLoader is great for simple text files.\\n\\nIt handles various encodings like UTF-8.\"),\n",
       " Document(metadata={'source': 'data\\\\sample.pdf'}, page_content='8. Blog / Thought Leadership Highlights\\n\\nProfessional headshots for business success\\n\\n\\n\\nImportance of visual storytelling in corporate branding\\n\\nTips for leveraging corporate videos for engagement\\n\\n9. Contact Information\\n\\nWebsite: Neuron.in\\n\\nContact form (highlighted visually)\\n\\n\\n\\nLocation: Noida, India\\n\\n\\n\\nSocial links (if available)\\n\\n10. Closing Page\\n\\n\\n\\nStrong brand statement: “With Neuron, your brand speaks visually.”\\n\\nCTA: “Explore our portfolio and elevate your business image today.”'),\n",
       " Document(metadata={'source': 'data\\\\sample.pdf'}, page_content=\"1. Cover Page\\n\\n\\n\\nLogo (from website)\\n\\nTitle: Neuron – Corporate Photography & Video Solutions\\n\\nTagline: Visual storytelling for modern brands\\n\\nHero image from homepage\\n\\n2. About Neuron\\n\\n\\n\\nIntroduction from homepage: “Elevate your brand's presence with our bespoke corporate video production and professional headshots in Pune. At Neuron, we help you unleash the power of visual storytelling to connect with your audience and showcase your corporate identity like never before.”\")]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "chroma_store = Chroma.from_documents(\n",
    "    documents=doc_chunks,\n",
    "    embedding=openai_embeddings,\n",
    "    persist_directory=\"chroma_db\"\n",
    ")\n",
    "\n",
    "chroma_store.persist()\n",
    "\n",
    "# Reload\n",
    "chroma_loaded = Chroma(\n",
    "    persist_directory=\"chroma_db\",\n",
    "    embedding_function=openai_embeddings\n",
    ")\n",
    "\n",
    "chroma_loaded.similarity_search(\"Explain embeddings\", k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9957d1c6",
   "metadata": {},
   "source": [
    "Task 9 — FAISS vs Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e14679",
   "metadata": {},
   "source": [
    "In-memory vs Persistent\n",
    "\n",
    "FAISS → primarily in-memory (can save index manually)\n",
    "\n",
    "Chroma → persistent by default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5355a8",
   "metadata": {},
   "source": [
    "Use cases for FAISS\n",
    "\n",
    "Fast similarity search\n",
    "\n",
    "Research experiments\n",
    "\n",
    "Lightweight production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d879b6d1",
   "metadata": {},
   "source": [
    "Use cases for Chroma\n",
    "\n",
    "Persistent applications\n",
    "\n",
    "RAG systems\n",
    "\n",
    "Long-running apps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa80e6e",
   "metadata": {},
   "source": [
    "PART 5 — End-to-End Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16aabf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipeline(\n",
    "    documents,\n",
    "    embedding_type=\"openai\",\n",
    "    vectorstore_type=\"faiss\"\n",
    "):\n",
    "    \n",
    "    # Select embedding\n",
    "    if embedding_type == \"openai\":\n",
    "        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    elif embedding_type == \"hf\":\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "        )\n",
    "    elif embedding_type == \"ollama\":\n",
    "        embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    else:\n",
    "        raise ValueError(\"Invalid embedding type\")\n",
    "    \n",
    "    # Select vector store\n",
    "    if vectorstore_type == \"faiss\":\n",
    "        vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "    elif vectorstore_type == \"chroma\":\n",
    "        vectorstore = Chroma.from_documents(\n",
    "            documents,\n",
    "            embeddings,\n",
    "            persist_directory=\"chroma_db\"\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Invalid vector store type\")\n",
    "    \n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f5322b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='9633fbe6-701b-4bcb-a39f-27db37c3f707', metadata={'source': 'data\\\\sample.txt'}, page_content=\"The quick brown fox jumps over the lazy dog.\\n\\nThis is the second line of the file.\\n\\nLangChain's TextLoader is great for simple text files.\\n\\nIt handles various encodings like UTF-8.\"),\n",
       " Document(id='f6ccc361-4bc1-4739-9002-38ac07cbce83', metadata={'source': 'data\\\\sample.pdf'}, page_content='o Mortal, Thug, Yatin Karyekar, Tisca Chopra, Sumedh Mudgalkar, Dynamo, Scout,\\n\\nRegaltos, etc.\\n\\nCorporate clients: Leading brands in tech and imaging\\n\\n\\n\\nInclude images of client work and celebrity shoots\\n\\n7. Why Choose Neuron\\n\\nCustom packages for budget & objectives\\n\\nTransform corporate image & marketing efforts\\n\\nExceptional value without compromising quality\\n\\nProven results reflected in #1 Google ranking\\n\\n8. Blog / Thought Leadership Highlights\\n\\nProfessional headshots for business success'),\n",
       " Document(id='40497a18-a88e-4beb-ae9e-62daa2a4a4d9', metadata={'source': 'data\\\\sample.csv'}, page_content='Name Age City Occupation Alice 30 New York Software Engineer Bob 25 Los Angeles Data Scientist Charlie 35 Chicago Product Manager David 28 Houston UX Designer')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore = build_pipeline(\n",
    "    doc_chunks,\n",
    "    embedding_type=\"openai\",\n",
    "    vectorstore_type=\"faiss\"\n",
    ")\n",
    "\n",
    "vectorstore.similarity_search(\"Explain vector databases\", k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00133cf7",
   "metadata": {},
   "source": [
    "Task 11 — Observations & Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc80d448",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2a4f6a5",
   "metadata": {},
   "source": [
    "Importance of Embeddings\n",
    "\n",
    "Embeddings convert text into numerical vectors that capture semantic meaning. Without embeddings, machines cannot measure text similarity effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f57f59",
   "metadata": {},
   "source": [
    "Why Vector Databases?\n",
    "\n",
    "Efficient similarity search\n",
    "\n",
    "Handles large datasets\n",
    "\n",
    "Fast retrieval\n",
    "\n",
    "Enables scalable search systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59b6f78",
   "metadata": {},
   "source": [
    "This pipeline:\n",
    "\n",
    "Converts documents → embeddings\n",
    "\n",
    "Stores embeddings in vector DB\n",
    "\n",
    "Retrieves relevant chunks\n",
    "\n",
    "Feeds them to LLM\n",
    "\n",
    "This is exactly how RAG systems retrieve context."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
